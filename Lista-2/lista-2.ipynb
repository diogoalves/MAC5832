{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diogo José Costa Alves \n",
    "\n",
    "### 1. Comente sobre o diagrama abaixo. O que o diagrama como um todo ilustra e o que cada componente representa?\n",
    "\n",
    "![diagrama](images/img-1.png \"Diagrama\")\n",
    "\n",
    "\n",
    "\n",
    "**Reposta**: \n",
    "O diagrama como todo descreve o problema de aprendizagem supervisionada. As caixas nos ajudam a enquadrar os conceitos gerais, as setas nos ajudam a perceber como eles se integram.\n",
    "\n",
    "\n",
    "**(1)** Função objetivo desconhecida. Essa caixa descreve a função ideal, desconhecida, que queremos aprender. Essa função mapeia o conjunto de entrada/features no domínio de saída da função $f:X \\to Y$. \n",
    "\n",
    "**(2)** Conjunto de treinamento. No aprendizado supervisionado, são os pares entre entradas/features e saída desejada/correta.\n",
    "\n",
    "**(3)** Distribuição de probabilidade de X. Quando descrevemos X como parte de uma distribuição de probabilidade, fica mais claro que podemos utilizar uma hipótese criada a partir de conjunto de treinamento para ser aplicada em dados fora do conjunto, já que ambos os dados vêm de uma mesma distribuição de probabilidade. Além disso, essa caixa parece descrever o caso em que a função de objetivo não é uma função determinística, mas sim uma função de probabilidade influenciada por $X$. Em outras palavras existe um ruído adicional na função objetivo.\n",
    "\n",
    "\n",
    "**(4)** Conjunto de Hipóteses. Descreve o espaço de possíveis hipóteses.\n",
    "\n",
    "**(5)** Hipótese final. Hipótese selecionada pelo algoritimo de aprendizagem. Tenta aproximar a função objetivo.\n",
    "\n",
    "**(6)** Algoritimo de aprendizagem. É o algoritimo utilizado para explorar o espaço de hipóteses a partir do conjunto de treinamento e selecionar uma hipótese final que melhor se aproxime a função objetivo. Em muitos casos, se trata de um problema de otimização onde uma função de custo deve ser minimizada. A qualificação de melhor ou pior hipótese é dada pela função de custo que é estabelecida de acordo com o problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. O que é $E_{in}$ e $E_{out}$?\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "São medidas de erro a partir de uma dada hipótese $h(x)$ escolhida frente a função objetivo $f(x)$.\n",
    "\n",
    "$E_{in}$ = Erro dentro da amostra. Corresponde a fração do conjunto de treinamento em que a hipótese testada difere da função objetivo. Dado o conjunto de treinamento, a função de hipótese, e a resposta correta, podemos calcular o quão distante a hipótese está da função objetivo. Calculamos o valor médio dentro do conjunto de treinamento. $E_{in} = \\frac{1}{N} \\sum_{n=1}^N e (h(x_n), f(x_n))$.\n",
    "\n",
    "$E_{out}$ = Erro fora da amostra. Na maioria das vezes não conseguimos calcular exatamente esse valor. É uma medida mais complexa de ser calculada, podemos estimar o $h(x)$ de acordo um uma distribuição de probabilidade da função objetivo $f(x)$. $E_{out} =E_x[e(h(x),f(x))]$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quando consideramos a formulação teórica de aprendizado de máquina, uma das possibilidades é investigar o valor $|E_{in} - E_{out}|$. O que esse valor expressa e por que nos interessa investigar ele?\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "Esse valor expressa a distância entre o erro dentro da amostra e o erro fora da amostra. Também é chamado de erro de generalização. \n",
    "\n",
    "Assumindo que os dados da amostra foram gerados a partir da mesma distribuição de probabilidade dos dados fora da amostra, essa diferença indicaria o quão boa seria a estimativa do erro fora da amostra realizada a quando realizada partir do valor do erro dentro da amostra.\n",
    "\n",
    "No aprendizado de máquina queremos manter esse valor o mais baixo possível, para que seja possível utilizar $E_{in}$ como proxy de $E_{out}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Por que apenas garantir $|E_{in} - E_{out}| \\lt \\epsilon$ pode não ser suficiente?\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "A medida de erro deve ser escolhida levando em consideração o domínio de aplicação. \n",
    "Podemos imaginar casos onde as medidas de erro seria adequada para uma aplicação mas não para outra.\n",
    "\n",
    "Continuando, fazer $E_{in}$ próximo $E_{out}$ diz apenas que o erro dentro da amostra é próximo do erro fora amostra. Informa que podemos ou não utilizar $E_{in}$ como proxy de $E_{out}$.\n",
    "\n",
    "No aprendizado de máquina, precisamos garantir que além de $E_{in}$ seja um bom proxy de $E_{out}$ (erro de generalização), que $E_{in}$ seja o mais baixo possível.\n",
    "Essa desigualdade não fala nada sobre  $E_{in}$ ser o mais baixo possível.\n",
    "\n",
    "Portanto, a minimização $|E_{in} - E_{out}| \\lt \\epsilon$ não é suficiente para garantir um escolha de uma boa hipótese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. A desigualdade de Hoeffding, no contexto de aprendizado de máquina, com respeito a uma certa hipótese $h$, é dada por:\n",
    "\n",
    "$P(|E_{in} - E_{out}| \\gt \\epsilon) \\le 2e^{-2\\epsilon^2N} $\n",
    "\n",
    "Explique o significado dessa desigualdade.\n",
    "\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "Assumindo que os dados da amostra foram gerados a partir da mesma distribuição de probabilidade dos dados fora da amostra, essa desigualdade tenta estabelecer, para uma hipótese específica, de forma probabilística, um limite superior para a condição que a distância entre $E_{in} e E_{out}$ seja superior a um valor limiar de erro $\\epsilon$, em outras palavras a probabilidade de uma aproximação ruim (superior ao limiar ($\\epsilon$)). Nós queremos que essa probabilidade seja a menor possível. Essa desigualdade também é conhecida como limite de generalization (*generalization bound*).\n",
    "\n",
    "O termo do lado esquerdo, calcula uma probabilidade e por isso tem o domínio [0,1]. Já o termo do lado direito está definido para valores superiores a 1. Nesses casos, o limite não informa nada. (O limite não limita).\n",
    "\n",
    "O aumento do limiar de erro $\\epsilon$, significa um relaxamento do requisito. \n",
    "No termo do lado esquerdo, um aumento de $\\epsilon$, pode ser lido, como que distância entre as estimativa dentro e fora dos exemplos aumente. Para a mesma hipótese e exemplos, o valor da probabilidade desse evento tende a diminuir quando $\\epsilon$ aumenta. No segundo termo, o $\\epsilon$ faz parte do expoente negativo, e o seu aumento condiz com a direção a diminuição do valor do termo do lado esquerdo.\n",
    "\n",
    "Já que não temos acesso ao valor de $E_{out}$, a ideia dessa desigualdade é estabelecer um critério para quando podemos utilizar $E_{in}$ como proxy de $E_{in}$.\n",
    "\n",
    "Continuando, o aumento do $N$ (número de exemplos) no segundo termo também no expoente negativo, também contribui para diminuição do valor do termo do lado esquerdo. Para a mesma hipótese, mantendo constante $\\epsilon$, a intuição é que quanto maior o número de exemplos maior a chance de que $E_{in}$ seja uma boa estimativa de $E_{out}$.\n",
    "\n",
    "Da mesma forma item anterior, ter um $E_{in}$ próximo ao $E_{out}$ é só parte do problema. O segundo requisito para garantir que dada hipótese é bom é que $E_{in}$ seja baixa o suficiente para aplicação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. A desigualdade de Hoeffding, no contexto de aprendizado de máquina, quando selecionamos uma hipótese de um espaço com $M$ hipóteses é dada por:\n",
    "\n",
    "$P(|E_{in} - E_{out}| \\gt \\epsilon) \\le 2Me^{-2\\epsilon^2N} $\n",
    "\n",
    "Comente sobre a diferença entre essa desigualdade e a do item anterior.\n",
    "\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "No item anterior tratamos a avaliação de uma única hipótese específica $h$, como se o $H$ (espaço de hipóteses) fosse limitado a apenas a essa hipótese $h$.\n",
    "\n",
    "Na prática, não é incomum, mesmo quando utilizamos modelos simples que o espaço de hipóteses $H$ seja muito maior do que 1.\n",
    "Por exemplo o modelo de Perceptron, quando utiliza valores reais para seus pesos, possui um espaço de hipóteses $H$ infinito.\n",
    "\n",
    "Nesse item, tentamos mais uma vez estabelecer quando poderíamos utilizar $E_{in}$ como proxy de $E_{out}$, só que agora tratatamos de um espaço de $M$ hipóteses. Nesse caso o valor de $M$ aumenta muito o limite superior da desigualdade a ponto de se tornar esse bound inútil na maioria dos casos práticos. \n",
    "\n",
    "No caso dos Perceptron, com espaço infinito, essa desigualdade não consegue garantir nada.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. O *bound* $2Me^{-2\\epsilon^2N}$ no item anterior foi obtido aplicando-se o *union-bound*. O que é *union-bound*?\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "*Union-bound* corresponde ao limite superior resultante de união da probabilidade de ocorrência de vários eventos. \n",
    "\n",
    "Essa operação não assume nada sobre a dependência/independência entre os eventos. \n",
    "\n",
    "No caso onde os eventos possuem muita sobreposição entre si, essa união será uma medida muito conservadora.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. O que são dicotomias? O que é *growth-function*? O que é *break point*? Qual a relação entre eles?\n",
    "\n",
    "**Resposta:**\n",
    "Dado que $H$ é o espaço de hipóteses de funções que mapeiam $X \\to {-1, +1}$. O número de hipóteses possíveis é dado por $|H|$\n",
    "\n",
    "**Dicotomia** é um subconjunto de $H$ definido apenas a partir em subconjunto de exemplos $(x_1, ..., x_N) \\in X $. Dado $H$ e $N$, o número de dicotomias possíveis é referenciado por $|H((x_1, ..., x_N)|$.\n",
    "\n",
    "\n",
    "**Growth-function** é definida como: Dado um espaço de hipóteses $H$, e um número $N$ de exemplos, **growth-function** é o número máximo de dicotomias que podem ser gerados. $m_H(N) = max |H((x_1, ..., x_N)|$. Para funções binárias, percebemos que a **Growth-function**, dado $N$ tem um limite superior menor igual a $2^N$. \n",
    "\n",
    "**Break point** é o primeiro valor de $N$ onde $m_H(N) \\lt 2^N$. É onde **quebra** o crescimento exponencial da função. \n",
    "\n",
    "Existe uma relação **POSITIVA** entre a expressividade de um conjunto de hipóteses, a diversidade de um conjunto de dicotomias e valor do break point. Espaço de hipóteses mais simples possuem break point menores. Espaço de hipóteses mais complexos, possuem break points maiores. Quanto menor o breakpoint melhor o limite gerado para **growth-function**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Escreve o que você entendeu sobre o processo envolvido na troca do $M$ em $2Me^{-2e^2N}$ pela **growth-function** $m_H(N)$. Qual é o novo *bound* obtido após a troca.\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "Um limite de generalização que utiliza infinito $M$ não informa nada. O processo de troca de $2Me^{-2e^2N}$ pela **growth-function** $m_H(N)$ é a tentativa de trocar um termo que é **infinito** por algo **finito**.\n",
    "\n",
    "O primeiro passo foi reconhecer que na construção $2Me^{-2e^2N}$ foi utilizada a **union-bound** que é estimativa extremamente conservadora quando pensamos que pode existir muitas superposições entre as hipóteses de $H$.\n",
    "\n",
    "A partir disso começou o processo de tentar descrever algo como sendo o número de hipóteses efetivas, como menos sobreposições de hipóteses.  Para isso foi proposta a **growth-function** $m_H(N)$.\n",
    "\n",
    "Durante a aula, conseguimos estabelecer a **growth-function** para um espaço de hipóteses $H$ que $X \\to {-1, +1}$. A partir do conceito de dicotomias estabelecemos que $m_H(N) = max |H((x_1, ..., x_N)|$, o é o número máximo de dicotomias para dado $N$ (número de exemplos). Nesse caso já conseguimos alterar o limite superior de algo infinito para no máximo $2^N$. O novo limite passa a ser $m_H(N) \\le 2^N$. \n",
    "\n",
    "A **growth-function** é uma função da classe de hipóteses e também de $N$. O livro estabelece o conceito de **break point**, conseguimos perceber uma relação entre o valor do break point e a complexidade do espaço de hipóteses. Por fim é estabelecido que quando existe **break point**, a **growth-function** se torna polinomial. Quanto menor o break point melhor o limite.\n",
    "\n",
    "Para esses casos, a **growth-function** é reescrita como um polinômio de grau $k$ (breakpoint) - 1. Nesses casos, com a  **growth-function** com crescimento polinomial o limite de generalização passa a fazer sentido quando utilizamos um $N$ suficientemente grande. \n",
    "\n",
    "Nos casos que não há breakpoints, o limite de generalização nunca será igual a zero e essa desigualdade não diz muita coisa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. O que é VC dimension? Como chegamos ao VC generalized bound (teorema 2.5 do livro) a partir da desigualdade de Hoeffding?\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "A definição é que VC dimension de um espaço de hipóteses $H$, descrito como $d_{VC}(H)$ ou simplesmente $d_{VC}$, é o maior valor de $N$ que o qual $m_H(N) = 2^N$. Se $m_H(N)=2^N$ para todos $N$, então $d_{VC} = \\infty$. Com isso podemos reescrever $k$ (break point) em função de $d_{VC}$, $k = d_{VC} + 1$.\n",
    "\n",
    "Com isso conseguimos reescrever a **growth-function** de crescimento polinomial de $m_H(N) \\le \\sum_{i=0}^{k-1} \\binom{N}{i}$ em função de $d_{VC}$.\n",
    "\n",
    "$m_H(N) \\le \\sum_{i=0}^{d_{VC}} \\binom{N}{i}$\n",
    "\n",
    "Dessa forma, $d_{VC}$ passa ser a ordem polinomial desse *bound*.\n",
    "\n",
    "Uma outra maneira de enxergar $d_{VC}$ é como uma medida efetiva dos números de parâmetros de um modelo. Quanto mais parâmetros um modelo possui, mas diverso é o espaço de hipóteses $H$, isso reflete em uma ordem polinomial maior na **grow-function**.\n",
    "\n",
    "\n",
    "Chegamos ao teorema 2.5 do livro substituindo $M$ da desigualdade de Hoeffding pela **growth-function**.  Só que a **growth-function** agora em função de $d_{VC}$. Esse *bound* faz sentindo apenas para os casos que  $d_{VC}$ não é infinito.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. A Equação (2.13) do livro texto é a seguinte\n",
    "\n",
    "$N \\gt \\frac{8}{e^2}ln(\\frac{4((2N)^{d_{VC}}+1)}{\\delta})$\n",
    "\n",
    "Comente quais as implicações práticas dela.\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "A implicações práticas são que, como dados suficientes, todas hipóteses de um espaço infinito de hipóteses $H$ com uma $d_{VC}$ finita irão aproximar bem $E_{in}$ e $E_{out}$, isto é, será possível generalizar do conjunto de treinamento para a vida real. Isso estabelece matematicamente a viabilidade do aprendizado de máquina a partir de espaço de hipóteses $H$ infinito.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Quais são as similaridades entre o VC analysis e o Bias-variance analysis?\n",
    "\n",
    "\n",
    "**Resposta:**\n",
    "\n",
    "Na VC analysis, $E_{out}$ é expresso como a soma de $E_{in}$ e o erro generalização que é limitado por $\\Omega$, a penalidade pela complexidade do modelo.\n",
    "\n",
    "Na Bias-variance analysis, $E_{out}$ é expresso com a soma do *bias* e *variance*.\n",
    "\n",
    "Os gráficos abaixo evidenciam essa relação.\n",
    "\n",
    "![gráfico](images/img-2.png \"gráfico\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "692e0e5b2dac9535ba397df32516123d15cee642b64f5380d2fb21772a29b53a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('qrcode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
