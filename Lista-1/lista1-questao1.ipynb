{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Diogo José Costa Alves\"  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 1.12 do livro texto\n",
    "\n",
    "Esse problema investiga como a mudança da medida de erro pode alterar o resultado do processo de aprendizagem. Você tem $N$ *data points* $y_1 \\leq ... \\leq y_N$ e gostaria de estimar um valor 'representativo'.\n",
    "\n",
    "**(a)** Se seu algorítimo busca a função de hipótese $h$ que minimiza a soma dos quadrados dos desvios da amostra,\n",
    " \n",
    " $E_{in}(h) = \\sum_{n=1}^N (h - y_n)^2$, \n",
    " \n",
    " então mostre que a a estimativa encontrada será a média da amostra, \n",
    " \n",
    " $h_{mean}=\\frac{1}{N} \\sum_{n=1}^Ny_n$.\n",
    "\n",
    " \n",
    " Resposta: O algorítmo de aprendizagem pode ser descrito como um processo de otimização. Quando falamos que o algorítmo de aprendizagem minimiza uma função de erro, estamos dizendo que o processo de otimização busca (dentre a possíveis funções de hipoteses) uma que atinja o menor valor da função de erro. Em outras palavras estamos buscando os pontos mínimos da função. Para a função dada, é possível encontrar o ponto de mínimo igualando sua primeira derivada a zero.\n",
    "\n",
    " $\\frac{dEin(h)}{dh} = 0$,\n",
    " \n",
    " $ ( \\sum_{n=1}^N (h - y_n)^2 )' = 0$\n",
    "\n",
    " $2 \\sum_{n=1}^N (h - y_n) = 0$,\n",
    " \n",
    " $h = \\frac{1}{N} \\sum_{n=1}^N y_n$\n",
    "\n",
    " Chegamos a um valor de $h$ igual a $h_{mean}$.\n",
    "\n",
    " Além disso, como a segunda derivada função é maior que zero, temos certeza que esse ponto é de mínimo.\n",
    "\n",
    " $\\frac{d^2Ein(h)}{d^2h} = 2N$,\n",
    "\n",
    " $ 2N \\gt 0 $\n",
    "\n",
    " Podemos dizer então que se nossa função de erro estiver minimizando os quadrados dos desvios da amostra a hipótese encontrada será a média dessa amostra.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Se seu algorítimo busca a função de hipótese $h$ que minimiza a soma dos desvios absolutos,\n",
    " \n",
    " $E_{in}(h) = \\sum_{n=1}^N |h -h y_n|$, \n",
    " \n",
    " então mostre que a a estimativa encontrada será a mediana da amostra $h_{med}$.\n",
    "\n",
    " Resposta: Da mesma forma da questão anterior, para minimizar essa função de erro buscamos igualamos sua primeira derizava a zero.\n",
    "\n",
    " $\\frac{dEin(h)}{dh} = 0$,\n",
    "\n",
    " $ (\\sum_{n=1}^N |h - y_n|)' = 0$,\n",
    "\n",
    " Nesse ponto, percebemos que a derivada é igual zero quando a soma dos termos positivos for igual a soma dos termos negativos, em outras palavras, quando $h$ é o valor central da amostra, a mediana. \n",
    "\n",
    " $ h = \\text{mediana} \\{y_1, ... , y_n\\} $,\n",
    "\n",
    " Chegamos a um valor que $h = h_{med}$\n",
    "\n",
    "  Podemos dizer então que se nossa função de erro estiver minimizando a soma dos desvios absolutos da amostra a hipótese encontrada será a mediana dessa amostra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Supondo que $y_n$ is pertubada  para $y_n + \\epsilon$, onde $\\epsilon \\to \\infty$. De forma que um único *data point* $y_n$ se torne um outlier. Qual o impacto nos estimadores $h_{mean}$ e $h_{med}$ ?\n",
    "\n",
    "Resposta: O primeiro estimador é muito impactado por essa alteração, já que esse outlier vai gerar $h_{mean} \\to \\infty$.\n",
    "\n",
    "Já o segundo estimador, não é afetado por este outlier, já que $h_{med}$ continua com o mesmo valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bad28c30d6adab66c37f0fdd3a6a074ccf8bbce91244602d9f8f13f5b849cf09"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
